# Pr√©diction de la demande d'√©nergie renouvelable

## 1. Probl√©matique et Contexte
Avec l'essor des √©nergies renouvelables, pr√©voir la demande d'√©nergie est crucial pour optimiser la production et la distribution. Ce projet vise √† pr√©dire la consommation d'√©lectricit√© √† partir de donn√©es r√©elles, en utilisant des techniques de machine learning et deep learning.

## 2. Donn√©es
- **Source** : [City Hall Electricity Usage ‚Äì Boston](https://data.boston.gov/dataset/city-hall-electricity-usage)
- **Description** :
  - Consommation √©lectrique mesur√©e toutes les 15 minutes √† la mairie de Boston (2016-2020)
  - Variable cible : `Total_Demand_KW`
  - Variables explicatives cr√©√©es : heure, jour de la semaine, mois, saison, week-end, lags temporels

### üì• Comment obtenir les donn√©es

**IMPORTANT** : Les fichiers de donn√©es ne sont pas inclus dans ce d√©p√¥t. Vous devez les t√©l√©charger vous-m√™me.

1. **T√©l√©charger le fichier source** :
   - Allez sur [City Hall Electricity Usage ‚Äì Boston](https://data.boston.gov/dataset/city-hall-electricity-usage)
   - T√©l√©chargez le fichier CSV (g√©n√©ralement nomm√© `city-hall-electricity-use.csv` ou similaire)
   - Placez-le √† la racine du projet avec le nom exact : `city-hall-electricity-use.csv`

2. **Format attendu** :
   - Le fichier doit contenir au minimum les colonnes :
     - `DateTime_Measured` : Date et heure au format datetime
     - `Total_Demand_KW` : Consommation √©lectrique en kilowatts

3. **Alternative** : Si vous avez vos propres donn√©es de consommation √©lectrique :
   - Assurez-vous qu'elles respectent le format ci-dessus
   - Renommez votre fichier en `city-hall-electricity-use.csv`
   - Placez-le √† la racine du projet

## 3. Pipeline de traitement
1. **Collecte et exploration des donn√©es**
2. **Pr√©traitement** :
   - Nettoyage (valeurs nulles, doublons, interpolation)
   - Feature engineering (variables temporelles, lags)
   - Normalisation/standardisation
   - Split train/validation/test (70/15/15)
3. **Mod√©lisation** :
   - Baseline : R√©gression lin√©aire, ARIMA
   - Machine Learning : RandomForest, XGBoost, LightGBM
   - Deep Learning : LSTM
4. **√âvaluation** :
   - M√©triques : RMSE, MAE, MAPE
   - Visualisations : courbes de pr√©diction, distribution des erreurs, importance des variables
5. **Optimisation** :
   - Tuning d'hyperparam√®tres (GridSearchCV sur LightGBM)
   - Am√©lioration des features
6. **Interface web** :
   - Application Streamlit compl√®te
   - Visualisations interactives
   - Pr√©diction personnalis√©e
   - Fonctionnalit√©s bonus (Prophet, PCA)

## 4. R√©sultats
| Mod√®le                | RMSE   | MAE   | MAPE (%) |
|-----------------------|--------|-------|----------|
| R√©gression lin√©aire   | 26.54  | 13.82 | 1.29     |
| RandomForest          | 33.65  | 16.88 | 1.71     |
| XGBoost               | 138.99 | 69.95 | 8.49     |
| LightGBM (d√©faut)     | 34.90  | 19.35 | 2.08     |
| LightGBM (optimis√©)   | 31.61  | 16.68 | -        |
| LSTM                  | 40.73  | 23.34 | -        |

- **La r√©gression lin√©aire reste la plus performante** sur ce jeu de donn√©es.
- **RandomForest et LightGBM** donnent de bons r√©sultats.
- **XGBoost** sous-performe (√† optimiser).
- **LSTM** fonctionne mais n'apporte pas de gain ici.

## 5. Interface Web Streamlit

### üöÄ Lancement de l'application
```bash
streamlit run app.py
```

### üì± Fonctionnalit√©s disponibles
1. **Accueil/Pr√©sentation** : Vue d'ensemble du projet
2. **Visualisation des donn√©es** : Exploration interactive des donn√©es d'entra√Ænement
3. **Comparaison des mod√®les** : Tableau comparatif des performances
4. **Importance des variables** : Analyse des features les plus importantes
5. **Pr√©diction personnalis√©e** : Interface pour faire des pr√©dictions avec le mod√®le LightGBM optimis√©
6. **T√©l√©chargement des r√©sultats** : Export des visualisations et r√©sultats
7. **Bonus - Analyse avanc√©e** :
   - **Prophet** : Pr√©vision de s√©ries temporelles avec saisonnalit√©s
   - **PCA** : R√©duction de dimension et visualisation des patterns cach√©s

## 6. Visualisations cl√©s
- `compare_models.png` : Comparaison des pr√©dictions de chaque mod√®le
- `zoom_predictions.png` : Zoom sur les 500 premi√®res pr√©dictions
- `error_distribution.png` : Distribution des erreurs
- `feature_importance_rf.png` : Importance des variables (RandomForest)

## 7. Fonctionnalit√©s Bonus

### Prophet - Pr√©vision avanc√©e
- Mod√®le d√©velopp√© par Facebook pour les s√©ries temporelles
- Gestion automatique des saisonnalit√©s et jours f√©ri√©s
- Interface pour choisir l'horizon de pr√©vision
- Visualisation des composantes (tendance, saisonnalit√©)

### PCA - R√©duction de dimension
- Analyse en Composantes Principales
- Visualisation des deux premi√®res composantes
- Analyse de la variance expliqu√©e
- D√©tection de patterns cach√©s dans les donn√©es

## 8. D√©fis rencontr√©s et solutions
- **Valeurs nulles et doublons** : Interpolation lin√©aire et agr√©gation par timestamp
- **Donn√©es bruit√©es** : Ajout de lags et de variables temporelles pour capter les patterns
- **Mod√®les deep learning** : Moins performants que les mod√®les classiques sur ce jeu de donn√©es
- **Interface web** : Int√©gration fluide de toutes les fonctionnalit√©s dans Streamlit

## 9. Perspectives et am√©liorations
- Ajouter des donn√©es m√©t√©o (temp√©rature, vent, ensoleillement) pour enrichir les variables explicatives
- Tester des mod√®les avanc√©s (Transformers pour s√©ries temporelles)
- D√©ploiement cloud de l'application web
- Ajout de fonctionnalit√©s de monitoring en temps r√©el
- Int√©gration de nouveaux datasets pour validation crois√©e

## 10. Structure du projet
- `devbook.md` : Suivi d√©taill√© du projet √©tape par √©tape
- `preprocessing.py` : Pipeline de pr√©paration des donn√©es
- `model_baseline.py` : Baseline (r√©gression lin√©aire, ARIMA)
- `model_ml.py` : Mod√®les ML (RandomForest, XGBoost, LightGBM)
- `model_lstm.py` : Mod√®le LSTM
- `compare_models.py` : Comparaison des mod√®les
- `eval_visualisation.py` : √âvaluation d√©taill√©e et visualisations
- `optimisation.py` : Tuning d'hyperparam√®tres
- `app.py` : Application web Streamlit
- `lgbm_optimise.pkl` : Mod√®le LightGBM optimis√© sauvegard√©

## 11. Installation et utilisation

### Pr√©requis
```bash
pip install -r requirements.txt
```

Ou manuellement :
```bash
pip install pandas numpy scikit-learn matplotlib seaborn lightgbm xgboost tensorflow streamlit prophet joblib statsmodels
```

### üìã Ordre d'ex√©cution des scripts

**IMPORTANT** : Suivez cet ordre pour ex√©cuter le projet correctement :

1. **T√©l√©charger les donn√©es** (voir section 2 ci-dessus)
   - Placez `city-hall-electricity-use.csv` √† la racine du projet

2. **Pr√©traitement des donn√©es** :
   ```bash
   python preprocessing.py
   ```
   - G√©n√®re : `data_train.csv`, `data_val.csv`, `data_test.csv`

3. **Entra√Ænement des mod√®les** (dans n'importe quel ordre) :
   ```bash
   python model_baseline.py      # Baseline (r√©gression lin√©aire, ARIMA)
   python model_ml.py            # Mod√®les ML (RandomForest, XGBoost, LightGBM)
   python model_lstm.py          # Mod√®le LSTM (peut prendre du temps)
   ```

4. **Optimisation du mod√®le** :
   ```bash
   python optimisation.py
   ```
   - G√©n√®re : `lgbm_optimise.pkl` (n√©cessaire pour l'application web)

5. **Comparaison et visualisation** :
   ```bash
   python compare_models.py
   python eval_visualisation.py
   ```

6. **Lancer l'application web** :
   ```bash
   streamlit run app.py
   ```
   - Ouvrez votre navigateur sur l'URL indiqu√©e (g√©n√©ralement http://localhost:8501)

### ‚ö†Ô∏è Notes importantes
- Les fichiers de donn√©es (`data_train.csv`, `data_val.csv`, `data_test.csv`) et le mod√®le (`lgbm_optimise.pkl`) sont g√©n√©r√©s automatiquement lors de l'ex√©cution des scripts
- Si vous modifiez les donn√©es source, relancez `preprocessing.py` pour r√©g√©n√©rer les datasets
- L'application web n√©cessite que `lgbm_optimise.pkl` existe (g√©n√©r√© par `optimisation.py`)

## 12. Auteur
**Abderrahman AJINOU** ‚Äì Universit√© Paris Cit√©  
N¬∞ √âtudiant : 22116322 ‚Äì abderrahman.ajinou@etu.u-paris.fr

### Objectifs acad√©miques
- Ma√Ætrise des concepts d'informatique (POO, interfaces graphiques)
- Efficacit√© des algorithmes et complexit√©
- Pr√©paration aux masters IA et Cybers√©curit√©
- Ambition : CAIO ou CTO 