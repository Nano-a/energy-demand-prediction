import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os

# 1. Chargement des donn√©es
DATA_PATH = 'city-hall-electricity-use.csv'

# V√©rification que le fichier existe
if not os.path.exists(DATA_PATH):
    print(f"‚ùå ERREUR : Le fichier '{DATA_PATH}' est introuvable !")
    print(f"\nüì• Pour r√©soudre ce probl√®me :")
    print(f"1. T√©l√©chargez les donn√©es depuis : https://data.boston.gov/dataset/city-hall-electricity-usage")
    print(f"2. Placez le fichier CSV √† la racine du projet avec le nom : {DATA_PATH}")
    print(f"3. Le fichier doit contenir les colonnes 'DateTime_Measured' et 'Total_Demand_KW'")
    print(f"\nüí° Alternative : Utilisez vos propres donn√©es en les renommant '{DATA_PATH}'")
    raise FileNotFoundError(f"Le fichier '{DATA_PATH}' est requis mais introuvable. Voir le README.md pour plus d'informations.")

print(f"‚úÖ Fichier trouv√© : {DATA_PATH}")
df = pd.read_csv(DATA_PATH, parse_dates=['DateTime_Measured'])
print(f"‚úÖ Donn√©es charg√©es : {len(df)} lignes")

# 2. Nettoyage des donn√©es
# Suppression des valeurs nulles ou aberrantes (Total_Demand_KW = 0)
df = df[df['Total_Demand_KW'] > 0].copy()

# Suppression des doublons de timestamps (on garde la moyenne)
df = df.groupby('DateTime_Measured', as_index=False)['Total_Demand_KW'].mean()

# V√©rification de la continuit√© temporelle
# On cr√©e un index temporel complet et on d√©tecte les trous
df = df.sort_values('DateTime_Measured')
df = df.set_index('DateTime_Measured')
full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')
df = df.reindex(full_range)

# On garde la colonne d'origine pour la demande
# Les valeurs manquantes sont interpol√©es lin√©airement
missing_before = df['Total_Demand_KW'].isna().sum()
df['Total_Demand_KW'] = df['Total_Demand_KW'].interpolate(method='linear')
missing_after = df['Total_Demand_KW'].isna().sum()

# 3. Feature engineering
# Ajout de variables temporelles

df['hour'] = df.index.hour
df['dayofweek'] = df.index.dayofweek
df['month'] = df.index.month
df['year'] = df.index.year
df['quarter'] = df.index.quarter
df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)

# Ajout de lags (d√©calages temporels)
for lag in [1, 4, 96]:  # 15 min, 1h, 1 jour
    df[f'lag_{lag}'] = df['Total_Demand_KW'].shift(lag)

# Suppression des premi√®res lignes avec NaN dues aux lags
df = df.dropna()

# 4. Normalisation/Standardisation
features = [col for col in df.columns if col != 'Total_Demand_KW']
scaler = StandardScaler()
df[features] = scaler.fit_transform(df[features])

# 5. Split train/val/test (70/15/15)
N = len(df)
train_end = int(0.7 * N)
val_end = int(0.85 * N)

df_train = df.iloc[:train_end]
df_val = df.iloc[train_end:val_end]
df_test = df.iloc[val_end:]

# Sauvegarde des datasets

df_train.to_csv('data_train.csv')
df_val.to_csv('data_val.csv')
df_test.to_csv('data_test.csv')

print(f"Pr√©traitement termin√©. Donn√©es sauvegard√©es : data_train.csv, data_val.csv, data_test.csv")
print(f"Valeurs manquantes avant interpolation : {missing_before}, apr√®s : {missing_after}") 